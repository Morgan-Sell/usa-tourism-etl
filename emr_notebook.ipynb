{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c225f0",
   "metadata": {},
   "source": [
    "# ETL Notebook\n",
    "\n",
    "Execute `etl.py` code in a notebook because EMR Notebook instance will not allow the running of a script in its terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71160e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c058acd999ad40d6936ed5ce92686137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, row_number\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, DateType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45386f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b67c923d6df40de9539013d213d3939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\" \n",
    "    Create spark entry point\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593cc64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ff43f4364b40bb95ffb3c50e85fc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_airports_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads and processes the raw airport data using Spark. \n",
    "    Returns the data as a semi-schematized parquet file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.read.option(\"header\", True).csv(input_data)\n",
    "\n",
    "    # Extract values from within columns\n",
    "    lat_long = F.split(df.coordinates, \",\")\n",
    "    df = df.withColumn(\"longitude\", lat_long.getItem(0))\n",
    "    df = df.withColumn(\"latitude\", lat_long.getItem(1))\n",
    "    region_split = F.split(df.iso_region, \"-\")\n",
    "    df = df.withColumn(\"state\", region_split.getItem(1))\n",
    "\n",
    "    # Select subset of original dataframe.\n",
    "    df2 = df.select([\"ident\",\n",
    "            \"iata_code\",\n",
    "            \"name\",\n",
    "            \"type\",\n",
    "            \"municipality\",\n",
    "            \"state\",\n",
    "            \"local_code\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"elevation_ft\"]).where(df.iso_country==\"US\")\n",
    "    \n",
    "    # Revise numeric values data types\n",
    "    df2 = df2.withColumn(\"latitude\", df2.latitude.cast('float')) \\\n",
    "            .withColumn(\"longitude\", df2.longitude.cast('float')) \\\n",
    "            .withColumn(\"elevation_fit\", df2.elevation_ft.cast('integer'))\n",
    "    \n",
    "    # Sort \n",
    "    df2 = df2.orderBy([\"state\", \"iata_code\"]) \\\n",
    "            .na.drop(subset='iata_code')\n",
    "    \n",
    "    # Export data to a parquet file\n",
    "    df2.write.partitionBy(\"state\").mode('overwrite').parquet(os.path.join(output_data, \"airports\"))\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81125f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d268a36f8b9a427f8bd68f3d1842879c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_cities_demographics_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads and processes the raw U.S. cities demographics data using Spark. \n",
    "    Returns the data as a semi-schematized parquet file.\n",
    "\n",
    "    \"\"\"\n",
    "    df = spark.read.option('header', True) \\\n",
    "                .option('delimiter', \";\") \\\n",
    "                .csv(input_data)\n",
    "    \n",
    "    df2 = df\n",
    "\n",
    "    for original, revised in config.USA_CITIES_RENAME_COLS.items():\n",
    "        df2 = df2.withColumnRenamed(original, revised)\n",
    "\n",
    "    df2 = df2.withColumn(\"state_city\", F.concat_ws(\"_\", df2.state_code, df2.city))\n",
    "\n",
    "    # Change data types to integers\n",
    "    for i_var in config.USA_CITIES_INTEGER_VARS:\n",
    "        df2 = df2.withColumn(i_var, df2[i_var].cast('integer'))\n",
    "    \n",
    "    # Change data types to floats\n",
    "    for f_var in config.USA_CITIES_FLOAT_VARS:\n",
    "        df2 = df2.withColumn(f_var, df2[f_var].cast('float'))\n",
    "\n",
    "    df2 = df2.dropDuplicates([\"state_city\"])\n",
    "\n",
    "    # Create race population group-by table.\n",
    "    race  = df2.select(\"state_city\", \"race\", \"race_pop\")\n",
    "    race = race.groupBy(\"state_city\").pivot(\"race\").agg(F.first(\"race_pop\"))\n",
    "\n",
    "    # join dataframes\n",
    "    df3 = df2.join(race, df2.state_city == race.state_city)\n",
    "    df3 = df3.drop(\"race\", \"race_pop\", \"state_city\", \"state_city\")\n",
    "             \n",
    "    for original, revised in config.RACE_RENAME_COLS.items():\n",
    "        df3 = df3.withColumnRenamed(original, revised)\n",
    "\n",
    "    df3 = df3.orderBy([\"state\", \"city\"])\n",
    "\n",
    "    # Export data to a parquet file\n",
    "    df3.write.partitionBy(\"state\").mode('overwrite').parquet(os.path.join(output_data, \"cities_demographics\"))\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3164040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d67a2563664add910a81faeb1f7bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_usa_temperature_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads global temperature files. \n",
    "    Returns a parquet file for the climate of U.S. cities.\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.read.option('header', True).csv(input_data)\n",
    "    df2 = df.select(\"*\").where((df.Country == \"United States\") & (df.dt > \"1969-12-31\"))\n",
    "    \n",
    "    for original, revised in config.TEMPERATURE_RENAME_COLS.items():\n",
    "        df2 = df2.withColumnRenamed(original, revised)\n",
    "    \n",
    "    df2 = df2.withColumn(\"lat_length\", F.length(\"latitude\")) \\\n",
    "            .withColumn(\"long_length\", F.length(\"longitude\")) \\\n",
    "            .withColumn(\"latitude_2\", F.expr(\"\"\"substr(latitude, 1, lat_length-1)\"\"\")) \\\n",
    "            .withColumn(\"longitude_2\", F.expr(\"\"\"substr(longitude, 1, long_length-1)\"\"\"))\n",
    "    \n",
    "    df2 = df2.withColumn(\"latitude\", df2.latitude_2.cast('float')) \\\n",
    "            .withColumn(\"longitude\", df2.longitude_2.cast('float'))\n",
    "\n",
    "    df2 = df2.withColumn(\"longitude\", -1 * col(\"longitude\")) \\\n",
    "            .withColumn(\"year\", year(df2.date)) \\\n",
    "            .withColumn(\"month\", month(df2.date)) \\\n",
    "            .drop(\"Country\", \"lat_length\", \"long_length\", \"latitude_2\", \"longitude_2\")\n",
    "    \n",
    "    df2 = df2.orderBy([\"date\", \"city\"])\n",
    "\n",
    "    df2.write.partitionBy(\"year\").mode('overwrite').parquet(os.path.join(output_data, \"usa_temperatures\"))\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "632de3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce09268a0ed04561bfd39bb77cf38284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_datetime(num_days):\n",
    "    \"\"\"\n",
    "    Converts a uni-codic numeric string value to a date object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        res = start + timedelta(days=int(float((num_days))))\n",
    "        return res.date()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5caecafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b1b61913a642968113730484ea3f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_usa_tourism_data(spark, tourism_data, airport_codes, country_codes, output_data):\n",
    "    \"\"\"\n",
    "    Loads and process the U.S. tourism SAS files.\n",
    "    Joins tourism data with airport_codes and countries.\n",
    "    Returns PySpark dataframe as partitioned parquet files.\n",
    "    \"\"\"\n",
    "\n",
    "    tourism = spark.read.parquet(tourism_data)\n",
    "    \n",
    "    airports = spark.read.option('header', True).csv(airport_codes)\n",
    "    countries = spark.read.option('header', True).csv(country_codes)\n",
    "\n",
    "    # Create airport-cities dictionary\n",
    "    airports2 = airports.withColumn(\"city\", F.split(col(\"airport\"), \",\").getItem(0))\n",
    "    airports2 = airports2.withColumn(\"city\", F.initcap(\"city\")) \\\n",
    "                        .drop(\"airport\")\n",
    "    \n",
    "    # Create country-I94 code dictionary\n",
    "    udf_datetime_from_sas = udf(lambda x: convert_datetime(x), DateType())\n",
    "    countries2 = countries.withColumn(\"country\", F.initcap(\"country\")) \\\n",
    "                        .withColumn(\"country_code\", countries.country_code.cast('integer'))\n",
    "\n",
    "    # Process tourism data\n",
    "    udf_datetime_from_sas = udf(lambda x: convert_datetime(x), DateType())\n",
    "\n",
    "    #tourism2 = tourism.withColumn(\"arrival_date\", udf_datetime_from_sas(col(\"arrdate\"))) \\\n",
    "    tourism2 = tourism.withColumn(\"arrival_date\", udf_datetime_from_sas(tourism.arrdate)) \\\n",
    "                .withColumn(\"departure_date\", udf_datetime_from_sas(tourism.depdate)) \\\n",
    "                .drop(*config.DROP_TOURISM_COLS)\n",
    "    \n",
    "    for original, renamed in config.TOURISM_RENAME_COLS.items():\n",
    "        tourism2 = tourism2.withColumnRenamed(original, renamed)\n",
    "\n",
    "    for feature in config.TOURISM_INTEGER_VARS:\n",
    "        tourism2 = tourism2.withColumn(feature, tourism2[feature].cast('integer'))\n",
    "    \n",
    "    # Create master dataframe by joining tourism2 and countries2 dataframes.\n",
    "    master = tourism2.join(countries2,\n",
    "                    tourism2.citizen_cntry_code == countries2.country_code,\n",
    "                    how ='left')\n",
    "    \n",
    "    master = master.withColumnRenamed(\"country\", \"citizen_country\") \\\n",
    "                    .drop(\"country_code\")\n",
    "    \n",
    "    master = master.join(countries2,\n",
    "                    master.residency_cntry_code == countries2.country_code,\n",
    "                    how='left')\n",
    "    \n",
    "    master = master.withColumnRenamed(\"country\", \"residency_country\") \\\n",
    "                    .drop(\"country_code\")\n",
    "    \n",
    "    # Join master and airports2 dataframes.\n",
    "    master = master.join(airports2, master.airport == airports2.airport_code, how='left')\n",
    "    master = master.withColumnRenamed(\"city\", \"airport_city\") \\\n",
    "                    .drop(\"airport_code\")\n",
    "\n",
    "    # Change the categorical values from integers/characters to descriptive strings.\n",
    "    travel_mode_func = udf(lambda x: config.MODE_OF_TRAVEL.get(x), StringType())\n",
    "    travel_reason_func = udf(lambda x: config.REASON_FOR_TRAVEL.get(x), StringType())\n",
    "    maritime_signals_func = udf(lambda x: config.MARITIME_SIGNAL_FLAGS.get(x), StringType())\n",
    "\n",
    "    master = master.withColumn(\"travel_mode\", travel_mode_func(master.travel_mode)) \\\n",
    "                        .withColumn(\"reason_for_travel\", travel_reason_func(master.reason_for_travel)) \\\n",
    "                        .withColumn(\"maritime_status_arrival\", maritime_signals_func(master.entdepa)) \\\n",
    "                        .withColumn(\"maritime_status_departure\", maritime_signals_func(master.entdepd)) \\\n",
    "                        .drop(\"entedepa\", \"entdepd\")\n",
    "    \n",
    "    # Add sequential ID\n",
    "    master = master.orderBy(\"arrival_date\") \\\n",
    "                .withColumn(\"tourism_id\", monotonically_increasing_id())\n",
    "    master = master.orderBy(\"tourism_id\")\n",
    "    #window = Window.orderBy(col(\"mono_increasing_id\"))\n",
    "\n",
    "    # Write master dataframe to parque files partitioned by year and month\n",
    "    master.write.partitionBy(\"arrival_yr\", \"arrival_month\").mode('overwrite').parquet(os.path.join(output_data, \"tourist_visits\"))\n",
    "    \n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3915d77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfe4d9fad5b46a9b6497f22ed72573c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_tables_loaded(airports_data, cities_data, weather_data, tourism_data):\n",
    "    \"\"\"\n",
    "    If any dataset has zero observations recorded/loaded, then an error warning is returned.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if airports_data.count() == 0:\n",
    "        print(\"ERROR: Airport data was not properly loaded\")\n",
    "    \n",
    "    elif cities_data.count() == 0:\n",
    "        print(\"ERROR: Cities data was not properly loaded\")\n",
    "        \n",
    "    elif weather_data.count() == 0:\n",
    "        print(\"ERROR: Weather data was not properly loaded\")\n",
    "    \n",
    "    elif tourism_data.count() == 0:\n",
    "        print(\"ERROR: Tourism data was not properly loaded\")\n",
    "        \n",
    "    else:\n",
    "        print(\"All tables successfully loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10952ee6",
   "metadata": {},
   "source": [
    "## Run ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd715de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fd2fdd9d3d4b1ea308920f27a090e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bfaa69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbb948ec72948269d463dda6f266739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update path whenever a new EMR cluster is created/used.\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.addPyFile(path=\"s3://aws-emr-resources-588336835903-us-west-2/notebooks/e-70ZSFY63SJ7TIRVLS0DQLQIN7/usa-tourism-etl/config.py\")\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00545344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feae584711e5420fa628d797c6758bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AIRPORT_DATA=\"s3a://udac-capstone/airports.csv\"\n",
    "TOURISM_DATA=\"s3a://udac-capstone/tourism_data/*.parquet\"\n",
    "USA_CITIES_DATA=\"s3a://udac-capstone/us_cities_demographics.csv\"\n",
    "WEATHER_DATA=\"s3a://udac-capstone/GlobalLandTemperaturesByCity.csv\"\n",
    "AIRPORT_CODES=\"s3a://udac-capstone/airport_codes.csv\"\n",
    "COUNTRY_CODES=\"s3a://udac-capstone/country_codes.csv\"\n",
    "OUTPUT_PATH = \"s3a://udac-capstone-output/\"\n",
    "\n",
    "airports_data = process_airports_data(spark, AIRPORT_DATA, OUTPUT_PATH)\n",
    "cities_data = process_cities_demographics_data(spark, USA_CITIES_DATA, OUTPUT_PATH)\n",
    "weather_data = process_usa_temperature_data(spark, WEATHER_DATA, OUTPUT_PATH)\n",
    "tourism_data = process_usa_tourism_data(spark, TOURISM_DATA, AIRPORT_CODES, COUNTRY_CODES, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b862e",
   "metadata": {},
   "source": [
    "## Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de3e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94be543df05d422d913c9c2c1ad99905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "name 'cities_data' is not defined\n",
      "Traceback (most recent call last):\n",
      "NameError: name 'cities_data' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_tables_loaded(airports_data, cities_data, weather_data, tourism_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d012c",
   "metadata": {},
   "source": [
    "## Query #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed4848",
   "metadata": {},
   "source": [
    "Where do the majority of tourists live?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b923add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec72bb688a142dcb371721feacc55ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|residency_country|total_people|\n",
      "+-----------------+------------+\n",
      "|   United Kingdom|      248096|\n",
      "|           France|      133861|\n",
      "|            Japan|      127386|\n",
      "|           Mexico|      121213|\n",
      "|          Germany|      103596|\n",
      "|       China, Prc|      103591|\n",
      "|           Brazil|       96482|\n",
      "|        Australia|       75838|\n",
      "|            India|       66494|\n",
      "|      South Korea|       58843|\n",
      "|       Argentina |       51442|\n",
      "|            Italy|       45998|\n",
      "|      Netherlands|       40491|\n",
      "|         Colombia|       37169|\n",
      "|           Israel|       33818|\n",
      "|            Spain|       31731|\n",
      "|      Switzerland|       31137|\n",
      "|          Ecuador|       31129|\n",
      "|           Sweden|       29155|\n",
      "|        Venezuela|       27847|\n",
      "+-----------------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "residency_count = tourism_data.where(tourism_data.residency_country.isNotNull()) \\\n",
    "                            .groupby(tourism_data.residency_country) \\\n",
    "                            .sum(\"num_people\") \\\n",
    "                            .select([col(\"residency_country\"), col(\"sum(num_people)\").alias(\"total_people\")]) \\\n",
    "                            .sort(col(\"total_people\").desc())\n",
    "\n",
    "residency_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ada3ca",
   "metadata": {},
   "source": [
    "## Query #2\n",
    "\n",
    "Is there a correlation between the number of foreigners visiting and percentage of foreigners living the in that city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee5c2d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405148f42f96425d8ad30dfebfef8058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "city_destination = tourism_data.where(col(\"airport_city\").isNotNull()) \\\n",
    "                            .groupby(col(\"airport_city\")) \\\n",
    "                            .sum(\"num_people\") \\\n",
    "                            .select([col(\"airport_city\"), col(\"sum(num_people)\").alias(\"total_visitors\")])\n",
    "\n",
    "\n",
    "prcnt_foreigners = cities_data.withColumn(\"prcnt_foreigners\", col(\"num_foreigners\") / col(\"total_pop\")) \\\n",
    "                            .select([col(\"city\"), F.round(col(\"prcnt_foreigners\"), 4).alias(\"prcnt_foreigners\")])\n",
    "\n",
    "\n",
    "cities_foreigners = city_destination.join(prcnt_foreigners, city_destination.airport_city == prcnt_foreigners.city, how='right') \\\n",
    "                                    .sort(col(\"total_visitors\").desc()) \\\n",
    "                                    .select(col(\"city\"), col(\"total_visitors\"), col(\"prcnt_foreigners\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fffae7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a280ae089c904b1893ddb8f3da33e9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+----------------+\n",
      "|           city|total_visitors|prcnt_foreigners|\n",
      "+---------------+--------------+----------------+\n",
      "|       New York|        337291|          0.3757|\n",
      "|          Miami|        244501|          0.5914|\n",
      "|    Los Angeles|        211671|           0.374|\n",
      "|        Orlando|        100815|          0.1866|\n",
      "|  San Francisco|         99646|          0.3437|\n",
      "|        Chicago|         84384|          0.2108|\n",
      "|        Houston|         66896|          0.3029|\n",
      "|Fort Lauderdale|         64558|          0.2664|\n",
      "|        Atlanta|         64376|           0.069|\n",
      "|      Las Vegas|         60110|          0.2046|\n",
      "|         Dallas|         47845|          0.2514|\n",
      "|         Boston|         37307|           0.284|\n",
      "|        Seattle|         29925|          0.1751|\n",
      "|        Phoenix|         24170|          0.1924|\n",
      "|        Detroit|         23116|          0.0589|\n",
      "|          Tampa|         16862|          0.1593|\n",
      "|   Philadelphia|         16857|           0.131|\n",
      "|         Denver|         11644|          0.1659|\n",
      "|      Charlotte|         11205|          0.1558|\n",
      "|     Fort Myers|         11053|          0.2076|\n",
      "+---------------+--------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "cities_foreigners.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8412e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac957c6bf6341aab5c86cd055ce2761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1562415438002099"
     ]
    }
   ],
   "source": [
    "cities_foreigners.stat.corr(\"total_visitors\", \"prcnt_foreigners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3d9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
