{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55707522",
   "metadata": {},
   "source": [
    "# USA Tourism ETL Notebook\n",
    "\n",
    "Execute etl.py code in a notebook because EMR Notebook instance will not allow the running of a script in its terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19af9867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc6cb01ae754fd08763c887b1eee10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1620063466694_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-2-10.us-west-2.compute.internal:20888/proxy/application_1620063466694_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-2-230.us-west-2.compute.internal:8042/node/containerlogs/container_1620063466694_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, row_number\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, DateType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6fc53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe09fee7dbc44e6eb20e678b7c2fd626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\" \n",
    "    Create spark entry point\n",
    "    \"\"\"\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa140f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10e6260bd5f4a4489c9cfa23ca46412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_airports_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads and processes the raw airport data using Spark. \n",
    "    Returns the data as a semi-schematized parquet file.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.read.option(\"header\", True).csv(input_data)\n",
    "\n",
    "    # Extract values from within columns\n",
    "    lat_long = F.split(df.coordinates, \",\")\n",
    "    df = df.withColumn(\"longitude\", lat_long.getItem(0))\n",
    "    df = df.withColumn(\"latitude\", lat_long.getItem(1))\n",
    "    region_split = F.split(df.iso_region, \"-\")\n",
    "    df = df.withColumn(\"state\", region_split.getItem(1))\n",
    "\n",
    "    # Select subset of original dataframe.\n",
    "    df2 = df.select([\"ident\",\n",
    "            \"iata_code\",\n",
    "            \"name\",\n",
    "            \"type\",\n",
    "            \"municipality\",\n",
    "            \"state\",\n",
    "            \"local_code\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"elevation_ft\"]).where(df.iso_country==\"US\")\n",
    "    \n",
    "    # Revise numeric values data types\n",
    "    df2 = df2.withColumn(\"latitude\", df2.latitude.cast('float')) \\\n",
    "            .withColumn(\"longitude\", df2.longitude.cast('float')) \\\n",
    "            .withColumn(\"elevation_fit\", df2.elevation_ft.cast('integer'))\n",
    "    \n",
    "    # Sort \n",
    "    df2 = df2.orderBy([\"state\", \"iata_code\"]) \\\n",
    "            .na.drop(subset='iata_code')\n",
    "    \n",
    "    # Export data to a parquet file\n",
    "    df2.write.partitionBy(\"state\").mode('overwrite').parquet(os.path.join(output_data, \"airports\"))\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf606307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28437d2e75a54be6981bc016f9d2f74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_cities_demographics_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads and processes the raw U.S. cities demographics data using Spark. \n",
    "    Returns the data as a semi-schematized parquet file.\n",
    "\n",
    "    \"\"\"\n",
    "    df = spark.read.option('header', True) \\\n",
    "                .option('delimiter', \";\") \\\n",
    "                .csv(input_data)\n",
    "    \n",
    "    df2 = df\n",
    "\n",
    "    for original, revised in config.USA_CITIES_RENAME_COLS.items():\n",
    "        df2 = df2.withColumnRenamed(original, revised)\n",
    "\n",
    "    df2 = df2.withColumn(\"state_city\", F.concat_ws(\"_\", df2.state_code, df2.city))\n",
    "\n",
    "    # Change data types to integers\n",
    "    for i_var in config.USA_CITIES_INTEGER_VARS:\n",
    "        df2 = df2.withColumn(i_var, df2[i_var].cast('integer'))\n",
    "    \n",
    "    # Change data types to floats\n",
    "    for f_var in config.USA_CITIES_FLOAT_VARS:\n",
    "        df2 = df2.withColumn(f_var, df2[f_var].cast('float'))\n",
    "\n",
    "    df2 = df2.dropDuplicates([\"state_city\"])\n",
    "\n",
    "    # Create race population group-by table.\n",
    "    race  = df2.select(\"state_city\", \"race\", \"race_pop\")\n",
    "    race = race.groupBy(\"state_city\").pivot(\"race\").agg(F.first(\"race_pop\"))\n",
    "\n",
    "    # join dataframes\n",
    "    df3 = df2.join(race, df2.state_city == race.state_city)\n",
    "    df3 = df3.drop(\"race\", \"race_pop\", \"state_city\", \"state_city\")\n",
    "             \n",
    "    for original, revised in config.RACE_RENAME_COLS.items():\n",
    "        df3 = df3.withColumnRenamed(original, revised)\n",
    "\n",
    "    df3 = df3.orderBy([\"state\", \"city\"])\n",
    "\n",
    "    # Export data to a parquet file\n",
    "    df3.write.partitionBy(\"state\").mode('overwrite').parquet(os.path.join(output_data, \"cities_demographics\"))\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485f4b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979ec2c1596c42d08eb061eeb3caed3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_usa_temperature_data(spark, input_data, output_data):\n",
    "    \"\"\"\n",
    "    Loads global temperature files. \n",
    "    Returns a parquet file for the climate of U.S. cities.\n",
    "    \"\"\"\n",
    "\n",
    "    df = spark.read.option('header', True).csv(input_data)\n",
    "    df2 = df.select(\"*\").where((df.Country == \"United States\") & (df.dt > \"1969-12-31\"))\n",
    "    \n",
    "    for original, revised in config.TEMPERATURE_RENAME_COLS.items():\n",
    "        df2 = df2.withColumnRenamed(original, revised)\n",
    "    \n",
    "    df2 = df2.withColumn(\"lat_length\", F.length(\"latitude\")) \\\n",
    "            .withColumn(\"long_length\", F.length(\"longitude\")) \\\n",
    "            .withColumn(\"latitude_2\", F.expr(\"\"\"substr(latitude, 1, lat_length-1)\"\"\")) \\\n",
    "            .withColumn(\"longitude_2\", F.expr(\"\"\"substr(longitude, 1, long_length-1)\"\"\"))\n",
    "    \n",
    "    df2 = df2.withColumn(\"latitude\", df2.latitude_2.cast('float')) \\\n",
    "            .withColumn(\"longitude\", df2.longitude_2.cast('float'))\n",
    "\n",
    "    df2 = df2.withColumn(\"longitude\", -1 * col(\"longitude\")) \\\n",
    "            .withColumn(\"year\", year(df2.date)) \\\n",
    "            .withColumn(\"month\", month(df2.date)) \\\n",
    "            .drop(\"Country\", \"lat_length\", \"long_length\", \"latitude_2\", \"longitude_2\")\n",
    "    \n",
    "    df2 = df2.orderBy([\"date\", \"city\"])\n",
    "\n",
    "    df2.write.partitionBy(\"year\").mode('overwrite').parquet(os.path.join(output_data, \"usa_temperatures\"))\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe9ebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87901edce8294855bd04399304f7e938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_datetime(num_days):\n",
    "    \"\"\"\n",
    "    Converts a uni-codic numeric string value to a date object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start = datetime(1960, 1, 1)\n",
    "        res = start + timedelta(days=int(float((num_days))))\n",
    "        return res.date()\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71201f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4619e2ec9d4d402fa43d806584df0bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_usa_tourism_data(spark, tourism_data, airport_codes, country_codes, output_data):\n",
    "    \"\"\"\n",
    "    Loads and process the U.S. tourism SAS files.\n",
    "    Joins tourism data with airport_codes and countries.\n",
    "    Returns PySpark dataframe as partitioned parquet files.\n",
    "    \"\"\"\n",
    "\n",
    "    tourism = spark.read.parquet(tourism_data)\n",
    "    \n",
    "    airports = spark.read.option('header', True).csv(airport_codes)\n",
    "    countries = spark.read.option('header', True).csv(country_codes)\n",
    "\n",
    "    # Create airport-cities dictionary\n",
    "    airports2 = airports.withColumn(\"city\", F.split(col(\"airport\"), \",\").getItem(0))\n",
    "    airports2 = airports2.withColumn(\"city\", F.initcap(\"city\")) \\\n",
    "                        .drop(\"airport\")\n",
    "    \n",
    "    # Create country-I94 code dictionary\n",
    "    udf_datetime_from_sas = udf(lambda x: convert_datetime(x), DateType())\n",
    "    countries2 = countries.withColumn(\"country\", F.initcap(\"country\")) \\\n",
    "                        .withColumn(\"country_code\", countries.country_code.cast('integer'))\n",
    "\n",
    "    # Process tourism data\n",
    "    udf_datetime_from_sas = udf(lambda x: convert_datetime(x), DateType())\n",
    "\n",
    "    #tourism2 = tourism.withColumn(\"arrival_date\", udf_datetime_from_sas(col(\"arrdate\"))) \\\n",
    "    tourism2 = tourism.withColumn(\"arrival_date\", udf_datetime_from_sas(tourism.arrdate)) \\\n",
    "                .withColumn(\"departure_date\", udf_datetime_from_sas(tourism.depdate)) \\\n",
    "                .drop(*config.DROP_TOURISM_COLS)\n",
    "    \n",
    "    for original, renamed in config.TOURISM_RENAME_COLS.items():\n",
    "        tourism2 = tourism2.withColumnRenamed(original, renamed)\n",
    "\n",
    "    for feature in config.TOURISM_INTEGER_VARS:\n",
    "        tourism2 = tourism2.withColumn(feature, tourism2[feature].cast('integer'))\n",
    "    \n",
    "    # Create master dataframe by joining tourism2 and countries2 dataframes.\n",
    "    master = tourism2.join(countries2,\n",
    "                    tourism2.citizen_cntry_code == countries2.country_code,\n",
    "                    how ='left')\n",
    "    \n",
    "    master = master.withColumnRenamed(\"country\", \"citizen_country\") \\\n",
    "                    .drop(\"country_code\")\n",
    "\n",
    "    master = master.join(countries2,\n",
    "                    master.residency_cntry_code == countries2.country_code,\n",
    "                    how='left')\n",
    "    \n",
    "    master = master.withColumnRenamed(\"country\", \"residency_country\") \\\n",
    "                    .drop(\"country_code\")\n",
    "    \n",
    "    # Join master and airports2 dataframes.\n",
    "    master = master.join(airports2, master.airport == airports2.airport_code, how='left')\n",
    "    master = master.withColumnRenamed(\"city\", \"airport_city\") \\\n",
    "                    .drop(\"airport_code\")\n",
    "\n",
    "    # Change the categorical values from integers/characters to descriptive strings.\n",
    "    travel_mode_func = udf(lambda x: config.MODE_OF_TRAVEL.get(x), StringType())\n",
    "    travel_reason_func = udf(lambda x: config.REASON_FOR_TRAVEL.get(x), StringType())\n",
    "    maritime_signals_func = udf(lambda x: config.MARITIME_SIGNAL_FLAGS.get(x), StringType())\n",
    "\n",
    "    master = master.withColumn(\"travel_mode\", travel_mode_func(master.travel_mode)) \\\n",
    "                        .withColumn(\"reason_for_travel\", travel_reason_func(master.reason_for_travel)) \\\n",
    "                        .withColumn(\"maritime_status_arrival\", maritime_signals_func(master.entdepa)) \\\n",
    "                        .withColumn(\"maritime_status_departure\", maritime_signals_func(master.entdepd)) \\\n",
    "                        .drop(\"entedepa\", \"entdepd\")\n",
    "    \n",
    "    # Add sequential ID\n",
    "    master = master.orderBy(\"arrival_date\") \\\n",
    "                .withColumn(\"tourism_id\", monotonically_increasing_id())\n",
    "    master = master.orderBy(\"tourism_id\")\n",
    "    #window = Window.orderBy(col(\"mono_increasing_id\"))\n",
    "\n",
    "    # Write master dataframe to parque files partitioned by year and month\n",
    "    master.write.partitionBy(\"arrival_yr\", \"arrival_month\").mode('overwrite').parquet(os.path.join(output_data, \"tourist_visits\"))\n",
    "    \n",
    "    return master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d900882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24fa1255d014e578c73eb9ccb002e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_for_successful_load(airports_url, cities_url, weather_url, tourism_url):\n",
    "    \"\"\"\n",
    "    Retrieves a sample of the data loaded into S3 to confirm data was successfully loaded.\n",
    "    \n",
    "    \"\"\"\n",
    "    airports_check = spark.read.parquet(airports_url)\n",
    "    cities_check = spark.read.parquet(cities_url)\n",
    "    weather_check = spark.read.parquet(weather_url)\n",
    "    tourism_check = spark.read.parquet(tourism_url)\n",
    "    \n",
    "    \n",
    "    if airports_check.count() == 0:\n",
    "        print(\"ERROR: Airport data was not properly loaded\")\n",
    "    \n",
    "    elif cities_check.count() == 0:\n",
    "        print(\"ERROR: Cities data was not properly loaded\")\n",
    "        \n",
    "    elif weather_check.count() == 0:\n",
    "        print(\"ERROR: Weather data was not properly loaded\")\n",
    "    \n",
    "    elif tourism_check.count() == 0:\n",
    "        print(\"ERROR: Tourism data was not properly loaded\")\n",
    "        \n",
    "    else:\n",
    "        print(\"All tables successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71fa58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845c392b14bf43909d5cc1d46cc6d807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_files_data_types(url, check_arr):\n",
    "    \"\"\"\n",
    "    Confirms if the dataset loaded into S3 contains the correct data type.\n",
    "    \"\"\"\n",
    "    num_incorrect = 0\n",
    "    df = spark.read.parquet(weather_url)\n",
    "    \n",
    "    for actual, check in zip(df.dtypes, check_arr):\n",
    "        if actual[1] != check:\n",
    "            num_correct += 1\n",
    "    \n",
    "    if num_incorrect > 0:\n",
    "        print(\"Column data types do not reconcile.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Column data types reconcile!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5818e",
   "metadata": {},
   "source": [
    "## Run ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb145f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6444fa0cf467dbd9ec285011bb7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1320c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aef8c4a76324746af44475a966d2f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update path whenever a new EMR cluster is created/used.\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.addPyFile(path=\"s3://aws-emr-resources-588336835903-us-west-2/notebooks/e-5NENBV094GZDUOE4YW4YS7A10/usa-tourism-etl/config.py\")\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f73e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19c36aec2254a38bde02ae6648cb94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AIRPORT_DATA=\"s3a://udac-capstone/airports.csv\"\n",
    "TOURISM_DATA=\"s3a://udac-capstone/tourism_data/*.parquet\"\n",
    "USA_CITIES_DATA=\"s3a://udac-capstone/us_cities_demographics.csv\"\n",
    "WEATHER_DATA=\"s3a://udac-capstone/GlobalLandTemperaturesByCity.csv\"\n",
    "AIRPORT_CODES=\"s3a://udac-capstone/airport_codes.csv\"\n",
    "COUNTRY_CODES=\"s3a://udac-capstone/country_codes.csv\"\n",
    "OUTPUT_PATH = \"s3a://udac-capstone-output/\"\n",
    "\n",
    "airports_data = process_airports_data(spark, AIRPORT_DATA, OUTPUT_PATH)\n",
    "cities_data = process_cities_demographics_data(spark, USA_CITIES_DATA, OUTPUT_PATH)\n",
    "weather_data = process_usa_temperature_data(spark, WEATHER_DATA, OUTPUT_PATH)\n",
    "tourism_data = process_usa_tourism_data(spark, TOURISM_DATA, AIRPORT_CODES, COUNTRY_CODES, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7b841",
   "metadata": {},
   "source": [
    "### Data Quality Check # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba2b3aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014a0b1c97084a76b1fd87d2ad8fca5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables successfully loaded!"
     ]
    }
   ],
   "source": [
    "# Confirm data was successfully loaded into an S3 bucket.\n",
    "airports_url = \"s3a://udac-capstone-output/airports/state=CA/*.parquet\"\n",
    "cities_url = \"s3a://udac-capstone-output/cities_demographics/state=California/*.parquet\"\n",
    "tourism_url = \"s3a://udac-capstone-output/tourist_visits/arrival_yr=2016/arrival_month=4/*.parquet\"\n",
    "weather_url = \"s3a://udac-capstone-output/usa_temperatures/year=1984/*.parquet\"\n",
    "\n",
    "check_for_successful_load(airports_url, cities_url, weather_url, tourism_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67897d9a",
   "metadata": {},
   "source": [
    "### Data Quality Check #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e8a45eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4147a1c8bf5046369296283ecb9080eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column data types reconcile!"
     ]
    }
   ],
   "source": [
    "correct_types = ['string', 'string', 'string', 'string', 'float', 'float', 'int']\n",
    "check_files_data_types(weather_url, correct_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1ef97",
   "metadata": {},
   "source": [
    "### Query #1\n",
    "Where do the majority of tourists live?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cafb955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66547552ea842fdbf92c558fbf1dc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|residency_country|total_people|\n",
      "+-----------------+------------+\n",
      "|   United Kingdom|      248096|\n",
      "|           France|      133861|\n",
      "|            Japan|      127386|\n",
      "|           Mexico|      121213|\n",
      "|          Germany|      103596|\n",
      "|       China, Prc|      103591|\n",
      "|           Brazil|       96482|\n",
      "|        Australia|       75838|\n",
      "|            India|       66494|\n",
      "|      South Korea|       58843|\n",
      "|       Argentina |       51442|\n",
      "|            Italy|       45998|\n",
      "|      Netherlands|       40491|\n",
      "|         Colombia|       37169|\n",
      "|           Israel|       33818|\n",
      "|            Spain|       31731|\n",
      "|      Switzerland|       31137|\n",
      "|          Ecuador|       31129|\n",
      "|           Sweden|       29155|\n",
      "|        Venezuela|       27847|\n",
      "+-----------------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "residency_count = tourism_data.where(tourism_data.residency_country.isNotNull()) \\\n",
    "                            .groupby(tourism_data.residency_country) \\\n",
    "                            .sum(\"num_people\") \\\n",
    "                            .select([col(\"residency_country\"), col(\"sum(num_people)\").alias(\"total_people\")]) \\\n",
    "                            .sort(col(\"total_people\").desc())\n",
    "\n",
    "residency_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f8443",
   "metadata": {},
   "source": [
    "### Query #2\n",
    "Is there a correlation between the number of foreigners visiting and percentage of foreigners living the in that city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31c1a0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208fa38fad6c4f8eb275ef6fa16afd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "city_destination = tourism_data.where(col(\"airport_city\").isNotNull()) \\\n",
    "                            .groupby(col(\"airport_city\")) \\\n",
    "                            .sum(\"num_people\") \\\n",
    "                            .select([col(\"airport_city\"), col(\"sum(num_people)\").alias(\"total_visitors\")])\n",
    "\n",
    "\n",
    "prcnt_foreigners = cities_data.withColumn(\"prcnt_foreigners\", col(\"num_foreigners\") / col(\"total_pop\")) \\\n",
    "                            .select([col(\"city\"), F.round(col(\"prcnt_foreigners\"), 4).alias(\"prcnt_foreigners\")])\n",
    "\n",
    "\n",
    "cities_foreigners = city_destination.join(prcnt_foreigners, city_destination.airport_city == prcnt_foreigners.city, how='right') \\\n",
    "                                    .sort(col(\"total_visitors\").desc()) \\\n",
    "                                    .select(col(\"city\"), col(\"total_visitors\"), col(\"prcnt_foreigners\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79b0d6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9638ccad172425e8604085e9e04e96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+----------------+\n",
      "|           city|total_visitors|prcnt_foreigners|\n",
      "+---------------+--------------+----------------+\n",
      "|       New York|        337291|          0.3757|\n",
      "|          Miami|        244501|          0.5914|\n",
      "|    Los Angeles|        211671|           0.374|\n",
      "|        Orlando|        100815|          0.1866|\n",
      "|  San Francisco|         99646|          0.3437|\n",
      "|        Chicago|         84384|          0.2108|\n",
      "|        Houston|         66896|          0.3029|\n",
      "|Fort Lauderdale|         64558|          0.2664|\n",
      "|        Atlanta|         64376|           0.069|\n",
      "|      Las Vegas|         60110|          0.2046|\n",
      "|         Dallas|         47845|          0.2514|\n",
      "|         Boston|         37307|           0.284|\n",
      "|        Seattle|         29925|          0.1751|\n",
      "|        Phoenix|         24170|          0.1924|\n",
      "|        Detroit|         23116|          0.0589|\n",
      "|          Tampa|         16862|          0.1593|\n",
      "|   Philadelphia|         16857|           0.131|\n",
      "|         Denver|         11644|          0.1659|\n",
      "|      Charlotte|         11205|          0.1558|\n",
      "|     Fort Myers|         11053|          0.2076|\n",
      "+---------------+--------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "cities_foreigners.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52bb15b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7cd7b89ec47c98634581095ac6ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15624154380020985"
     ]
    }
   ],
   "source": [
    "cities_foreigners.stat.corr(\"total_visitors\", \"prcnt_foreigners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e732bde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
