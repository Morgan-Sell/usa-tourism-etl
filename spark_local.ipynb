{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-brooklyn",
   "metadata": {},
   "source": [
    "# Spark Local Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, row_number\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, DateType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-insured",
   "metadata": {},
   "source": [
    "## Configure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = \"test_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "excited-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure = SparkConf().setAppName('udac_config').setMaster('local')\n",
    "sc = SparkContext(conf = configure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "complex-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getOrCreate modifies the parameters of existing Spark Session\n",
    "spark = SparkSession.builder.appName('udac_cap').config('config option', 'config value').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "macro-fluid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.app.id', 'local-1616794435947'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/morgan/Documents/10_Udacity/data_eng_nano/usa-tourism-etl/spark-warehouse'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.port', '63786'),\n",
       " ('spark.driver.host', '10.0.0.223'),\n",
       " ('spark.app.name', 'udac_config'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.app.startTime', '1616794435024'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-ethics",
   "metadata": {},
   "source": [
    "### Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "right-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = spark.read.option(\"header\", True).csv(\"data/airport_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "known-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = F.split(airports.coordinates, \",\")\n",
    "airports = airports.withColumn('longitude', lat_long.getItem(0))\n",
    "airports = airports.withColumn('latitude', lat_long.getItem(1))\n",
    "\n",
    "region_split = F.split(airports.iso_region, \"-\")\n",
    "airports = airports.withColumn('state', region_split.getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attractive-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.select(['ident',\n",
    "                 'iata_code',\n",
    "                 'name','type',\n",
    "                 'municipality',\n",
    "                 'state',\n",
    "                 'local_code',\n",
    "                 'latitude',\n",
    "                 'longitude',\n",
    "                 'elevation_ft']).where(airports.iso_country==\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "embedded-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.sort('iata_code', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "congressional-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.na.drop(subset='iata_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outside-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.withColumn(\"latitude\", airports.latitude.cast('float')) \\\n",
    "                    .withColumn(\"longitude\", airports.longitude.cast('float')) \\\n",
    "                    .withColumn(\"elevation_fit\", airports.elevation_ft.cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "proof-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+-------------+\n",
      "|ident|iata_code|                name|          type| municipality|state|local_code|latitude|longitude|elevation_ft|elevation_fit|\n",
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+-------------+\n",
      "| KAAF|      AAF|Apalachicola Regi...| small_airport| Apalachicola|   FL|       AAF| 29.7275| -85.0275|          20|           20|\n",
      "| KAAP|      AAP|      Andrau Airpark|        closed|      Houston|   TX|       AAP| 29.7225| -95.5883|          79|           79|\n",
      "| KABE|      ABE|Lehigh Valley Int...|medium_airport|    Allentown|   PA|       ABE| 40.6521| -75.4408|         393|          393|\n",
      "| KABI|      ABI|Abilene Regional ...|medium_airport|      Abilene|   TX|       ABI| 32.4113| -99.6819|        1791|         1791|\n",
      "| PAFM|      ABL|      Ambler Airport|medium_airport|       Ambler|   AK|       AFM| 67.1063| -157.857|         334|          334|\n",
      "| KABQ|      ABQ|Albuquerque Inter...| large_airport|  Albuquerque|   NM|       ABQ| 35.0402| -106.609|        5355|         5355|\n",
      "| KABR|      ABR|Aberdeen Regional...|medium_airport|     Aberdeen|   SD|       ABR| 45.4491| -98.4218|        1302|         1302|\n",
      "| KABY|      ABY|Southwest Georgia...|medium_airport|       Albany|   GA|       ABY| 31.5355| -84.1945|         197|          197|\n",
      "| KACB|      ACB|Antrim County Air...| small_airport|     Bellaire|   MI|       ACB| 44.9886| -85.1984|         623|          623|\n",
      "| KACK|      ACK|Nantucket Memoria...|medium_airport|    Nantucket|   MA|       ACK| 41.2531| -70.0602|          47|           47|\n",
      "| KACT|      ACT|Waco Regional Air...|medium_airport|         Waco|   TX|       ACT| 31.6113| -97.2305|         516|          516|\n",
      "| KACV|      ACV|California Redwoo...|medium_airport|Arcata/Eureka|   CA|       ACV| 40.9781| -124.109|         221|          221|\n",
      "| KACY|      ACY|Atlantic City Int...|medium_airport|Atlantic City|   NJ|       ACY| 39.4576| -74.5772|          75|           75|\n",
      "| KADG|      ADG|Lenawee County Ai...| small_airport|       Adrian|   MI|       ADG| 41.8677| -84.0773|         798|          798|\n",
      "| PADK|      ADK|        Adak Airport|medium_airport|  Adak Island|   AK|       ADK|  51.878| -176.646|          18|           18|\n",
      "| KADM|      ADM|Ardmore Municipal...| small_airport|      Ardmore|   OK|       ADM|34.30301|-97.01963|         777|          777|\n",
      "| PADQ|      ADQ|      Kodiak Airport|medium_airport|       Kodiak|   AK|       ADQ|   57.75| -152.494|          78|           78|\n",
      "| KPHH|      ADR|Robert F Swinnie ...| small_airport|      Andrews|   SC|       PHH| 33.4517| -79.5262|          26|           26|\n",
      "| KADS|      ADS|     Addison Airport| small_airport|       Dallas|   TX|       ADS| 32.9686| -96.8364|         644|          644|\n",
      "| KADH|      ADT|Ada Regional Airport| small_airport|          Ada|   OK|       ADH| 34.8043| -96.6713|        1016|         1016|\n",
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-torture",
   "metadata": {},
   "source": [
    "#### Successfully created parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "#airports.write.mode('overwrite').parquet(os.path.join(output_data, \"airports\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-pipeline",
   "metadata": {},
   "source": [
    "---\n",
    "## USA Cities Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "average-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = spark.read.option('header', True) \\\n",
    "        .option('delimiter', \";\") \\\n",
    "        .csv(\"data/us_cities_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "peaceful-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.withColumnRenamed(\"City\", \"city\") \\\n",
    "        .withColumnRenamed(\"State\", \"state\") \\\n",
    "        .withColumnRenamed(\"Median Age\", \"median_age\") \\\n",
    "        .withColumnRenamed(\"Male Population\", \"male_pop\") \\\n",
    "        .withColumnRenamed(\"Female Population\", \"female_pop\") \\\n",
    "        .withColumnRenamed(\"Total Population\", \"total_pop\") \\\n",
    "        .withColumnRenamed(\"Number of Veterans\", \"num_veterans\") \\\n",
    "        .withColumnRenamed(\"Foreign-born\", \"num_foreigners\") \\\n",
    "        .withColumnRenamed(\"Average Household Size\", \"avg_household_size\") \\\n",
    "        .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "        .withColumnRenamed(\"Race\", \"race\") \\\n",
    "        .withColumnRenamed(\"Count\", \"race_pop\")\n",
    "\n",
    "cities = cities.withColumn(\"state_city\", F.concat_ws(\"_\", cities.state_code, cities.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outstanding-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_vars = [\"male_pop\", \"female_pop\", \"total_pop\", \"num_veterans\", \"num_foreigners\", \"race_pop\"]\n",
    "float_vars = [\"median_age\", \"avg_household_size\"]\n",
    "\n",
    "for i_var in integer_vars:\n",
    "    cities = cities.withColumn(i_var, cities[i_var].cast('integer'))\n",
    "    \n",
    "for f_var in float_vars:\n",
    "    cities = cities.withColumn(f_var, cities[f_var].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "drawn-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2 = cities.dropDuplicates([\"state_city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "grave-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_count = cities.select(\"state_city\", \"race\", \"race_pop\")\n",
    "race_count = race_count.withColumn(\"race_pop\", race_count.race_pop.cast('float'))\n",
    "race_count = race_count.groupBy(\"state_city\").pivot(\"race\").agg(F.first(\"race_pop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "political-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_final = cities2.join(race_count, cities2.state_city == race_count.state_city)\n",
    "cities_final = cities_final.drop(\"race\", \"race_pop\", \"state_city\", \"state_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dental-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_final = cities_final.withColumnRenamed(\"American Indian and Alaska Native\", \"native_american_pop\") \\\n",
    "                            .withColumnRenamed(\"Asian\", \"asian_pop\") \\\n",
    "                            .withColumnRenamed(\"Black or African-American\", \"black_american_pop\") \\\n",
    "                            .withColumnRenamed(\"Hispanic or Latino\", \"hispanic_pop\") \\\n",
    "                            .withColumnRenamed(\"White\", \"white_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "altered-wallace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_pop: integer (nullable = true)\n",
      " |-- female_pop: integer (nullable = true)\n",
      " |-- total_pop: integer (nullable = true)\n",
      " |-- num_veterans: integer (nullable = true)\n",
      " |-- num_foreigners: integer (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- native_american_pop: float (nullable = true)\n",
      " |-- asian_pop: float (nullable = true)\n",
      " |-- black_american_pop: float (nullable = true)\n",
      " |-- hispanic_pop: float (nullable = true)\n",
      " |-- white_pop: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-saver",
   "metadata": {},
   "source": [
    "#### Successfully created parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "magnetic-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cities_final.write.mode('overwrite').parquet(os.path.join(output_data, \"cities\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-uruguay",
   "metadata": {},
   "source": [
    "---\n",
    "## USA Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "flexible-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = spark.read.option('header', True) \\\n",
    "                .csv(\"data/GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "explicit-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "theoretical-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "impaired-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures.select(\"*\").where((temperatures.Country == \"United States\") & (temperatures.dt > \"1969-12-31\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "removable-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures.withColumnRenamed(\"dt\", \"date_time\") \\\n",
    "                            .withColumnRenamed(\"AverageTemperature\", \"avg_daily_temp\") \\\n",
    "                            .withColumnRenamed(\"AverageTemperatureUncertainty\", \"avg_temp_temp_uncertainty\") \\\n",
    "                            .withColumnRenamed(\"City\", \"city\") \\\n",
    "                            .withColumnRenamed(\"Latitude\", \"latitude\") \\\n",
    "                            .withColumnRenamed(\"Longitude\", \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bronze-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures.withColumn(\"lat_length\", F.length(\"latitude\")) \\\n",
    "                            .withColumn(\"long_length\", F.length(\"longitude\")) \\\n",
    "                            .withColumn(\"latitude_2\", F.expr(\"\"\"substr(latitude, 1, lat_length-1)\"\"\")) \\\n",
    "                            .withColumn(\"longitude_2\", F.expr(\"\"\"substr(longitude, 1, long_length-1)\"\"\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "searching-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures.withColumn(\"latitude\", temperatures.latitude_2.cast('float')) \\\n",
    "                            .withColumn(\"longitude\", temperatures.longitude_2.cast('float'))\n",
    "\n",
    "temperatures = temperatures.withColumn(\"longitude\", -1 * col(\"longitude\"))\n",
    "\n",
    "temperatures = temperatures.drop(\"Country\", \"lat_length\", \"long_length\", \"latitude_2\", \"longitude_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "legal-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------------------+-------+--------+---------+\n",
      "| date_time|avg_daily_temp|avg_temp_temp_uncertainty|   city|latitude|longitude|\n",
      "+----------+--------------+-------------------------+-------+--------+---------+\n",
      "|1970-01-01|         3.969|                    0.289|Abilene|   32.95|  -100.53|\n",
      "|1970-02-01|         8.463|                    0.177|Abilene|   32.95|  -100.53|\n",
      "+----------+--------------+-------------------------+-------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "appreciated-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#temperatures.write.mode('overwrite').parquet(os.path.join(output_data, \"temperatures\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-poultry",
   "metadata": {},
   "source": [
    "---\n",
    "## Visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-legislation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "attended-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = spark.read.option('header', True) \\\n",
    "            .option('delimiter', \",\") \\\n",
    "            .csv(\"data/immigration_data_sample.csv\")\n",
    "\n",
    "df2 = spark.read.option('header', True).csv(\"data/airport_dict.csv\")\n",
    "\n",
    "df3 = spark.read.option('header', True).csv(\"data/country_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bizarre-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_dict = df2.withColumn(\"city\", F.split(col(\"airport\"), \",\").getItem(0)) \\\n",
    "                .withColumn(\"state\", F.split(col(\"airport\"), \",\").getItem(1))\n",
    "\n",
    "cities_dict = cities_dict.withColumn(\"city\", F.initcap(\"city\")) \\\n",
    "                        .drop(\"airport\", \"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "closed-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|airport_code|     city|\n",
      "+------------+---------+\n",
      "|         ALC|    Alcan|\n",
      "|         ANC|Anchorage|\n",
      "+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_dict.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "understanding-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = df3.withColumn(\"country\", F.initcap(\"country\")) \\\n",
    "                    .withColumn(\"country_code\", df3[\"country_code\"].cast('integer')) \\\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "restricted-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP FOR LATER REFERENCE\n",
    "\n",
    "# deleteWhitespaceUDF = udf(lambda s: s.replace(\" \", \"\") if type(s) is str else s, StringType())\n",
    "# deleteApostropheUDF = udf(lambda s: s.replace(\"''\", \"\") if type(s) is str else s, StringType())\n",
    "# airports2_dict = airports2_dict.withColumn(\"state_cleaned\", F.expr(\"substring(state, 1, length(state)-1)\"))\n",
    "# airports2_dict = airports2_dict.withColumn(\"state\", deleteApostropheUDF(\"state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "collaborative-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits2 = visits.drop(\"insnum\", \"dtadfile\", \"fltno\", 'i94bir', \"occup\", \"matflag\", \"admnum\", \"entdepu\", \"visapost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suspected-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits2 = visits2.withColumnRenamed(\"_c0\", \"visit_id\") \\\n",
    "            .withColumnRenamed(\"cicid\", \"citizen_id\") \\\n",
    "            .withColumnRenamed(\"i94yr\", \"arrival_yr\") \\\n",
    "            .withColumnRenamed(\"i94mon\", \"arrival_month\") \\\n",
    "            .withColumnRenamed(\"i94cit\", \"citizen_cntry_code\") \\\n",
    "            .withColumnRenamed(\"i94res\", \"residency_cntry_code\") \\\n",
    "            .withColumnRenamed(\"i94port\", \"airport\") \\\n",
    "            .withColumnRenamed(\"arrdate\", \"arrival_date\") \\\n",
    "            .withColumnRenamed(\"i94mode\", \"travel_mode\") \\\n",
    "            .withColumnRenamed(\"i94addr\", \"airport_state\") \\\n",
    "            .withColumnRenamed(\"depdate\", \"departure_date\") \\\n",
    "            .withColumnRenamed(\"i94visa\", \"reason_for_travel\") \\\n",
    "            .withColumnRenamed(\"count\", \"num_people\") \\\n",
    "            .withColumnRenamed(\"biryear\", \"birth_year\") \\\n",
    "            .withColumnRenamed(\"visatype\", \"visa_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "broadband-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- visit_id: string (nullable = true)\n",
      " |-- citizen_id: string (nullable = true)\n",
      " |-- arrival_yr: string (nullable = true)\n",
      " |-- arrival_month: string (nullable = true)\n",
      " |-- citizen_cntry_code: string (nullable = true)\n",
      " |-- residency_cntry_code: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- travel_mode: string (nullable = true)\n",
      " |-- airport_state: string (nullable = true)\n",
      " |-- departure_date: string (nullable = true)\n",
      " |-- reason_for_travel: string (nullable = true)\n",
      " |-- num_people: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- birth_year: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visits2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pursuant-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_to_integer = [\"citizen_id\", \"arrival_yr\", \"arrival_month\", \"citizen_cntry_code\", \"residency_cntry_code\", \"travel_mode\",\n",
    "                \"reason_for_travel\", \"num_people\", \"birth_year\"]\n",
    "\n",
    "for feature in cast_to_integer:\n",
    "    visits2 = visits2.withColumn(feature, visits2[feature].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "moderate-petroleum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+\n",
      "|visit_id|citizen_id|arrival_yr|arrival_month|citizen_cntry_code|residency_cntry_code|airport|arrival_date|travel_mode|airport_state|departure_date|reason_for_travel|num_people|entdepa|entdepd|birth_year| dtaddto|gender|airline|visa_type|\n",
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+\n",
      "| 2027561|   4084316|      2016|            4|               209|                 209|    HHW|     20566.0|          1|           HI|       20573.0|                2|         1|      G|      O|      1955|07202016|     F|     JL|       WT|\n",
      "| 2171295|   4422636|      2016|            4|               582|                 582|    MCA|     20567.0|          1|           TX|       20568.0|                2|         1|      G|      R|      1990|10222016|     M|    *GA|       B2|\n",
      "|  589494|   1195600|      2016|            4|               148|                 112|    OGG|     20551.0|          1|           FL|       20571.0|                2|         1|      G|      O|      1940|07052016|     M|     LH|       WT|\n",
      "| 2631158|   5291768|      2016|            4|               297|                 297|    LOS|     20572.0|          1|           CA|       20581.0|                2|         1|      G|      O|      1991|10272016|     M|     QR|       B2|\n",
      "| 3032257|    985523|      2016|            4|               111|                 111|    CHM|     20550.0|          3|           NY|       20553.0|                2|         1|      Z|      K|      1997|07042016|     F|   null|       WT|\n",
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visits2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-triple",
   "metadata": {},
   "source": [
    "#### Join all 3 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "hazardous-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "tourism_final = visits2.join(countries_dict, visits2.citizen_cntry_code == countries_dict.country_code, how ='left')\n",
    "tourism_final = tourism_final.withColumnRenamed(\"country\", \"citizen_country\") \\\n",
    "                            .drop(\"country_code\")\n",
    "\n",
    "tourism_final = tourism_final.join(countries_dict, tourism_final.residency_cntry_code == countries_dict.country_code, how='left')\n",
    "tourism_final = tourism_final.withColumnRenamed(\"country\", \"residency_country\") \\\n",
    "                            .drop(\"country_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "pacific-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "tourism_final = tourism_final.join(cities_dict, tourism_final.airport == cities_dict.airport_code, how='left')\n",
    "tourism_final = tourism_final.withColumnRenamed(\"city\", \"airport_city\") \\\n",
    "                            .drop(\"airport_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "joint-dictionary",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9fc69af59727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtourism_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtourism_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"base_date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1970-01-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/udac_cap/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \"\"\"\n\u001b[0;32m-> 2454\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "tourism_final = tourism_final.withColumn(\"base_date\", \"1970-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "young-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+---------------+-----------------+--------------+-------------------+\n",
      "|visit_id|citizen_id|arrival_yr|arrival_month|citizen_cntry_code|residency_cntry_code|airport|arrival_date|travel_mode|airport_state|departure_date|reason_for_travel|num_people|entdepa|entdepd|birth_year| dtaddto|gender|airline|visa_type|citizen_country|residency_country|  airport_city|     arrival_date_x|\n",
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+---------------+-----------------+--------------+-------------------+\n",
      "| 2027561|   4084316|      2016|            4|               209|                 209|    HHW|     20566.0|          1|           HI|       20573.0|                2|         1|      G|      O|      1955|07202016|     F|     JL|       WT|          Japan|            Japan|      Honolulu|1969-12-31 21:42:46|\n",
      "| 2171295|   4422636|      2016|            4|               582|                 582|    MCA|     20567.0|          1|           TX|       20568.0|                2|         1|      G|      R|      1990|10222016|     M|    *GA|       B2|         Mexico|           Mexico|       Mcallen|1969-12-31 21:42:47|\n",
      "|  589494|   1195600|      2016|            4|               148|                 112|    OGG|     20551.0|          1|           FL|       20571.0|                2|         1|      G|      O|      1940|07052016|     M|     LH|       WT|           null|          Germany|Kahului - Maui|1969-12-31 21:42:31|\n",
      "| 2631158|   5291768|      2016|            4|               297|                 297|    LOS|     20572.0|          1|           CA|       20581.0|                2|         1|      G|      O|      1991|10272016|     M|     QR|       B2|          Qatar|            Qatar|   Los Angeles|1969-12-31 21:42:52|\n",
      "| 3032257|    985523|      2016|            4|               111|                 111|    CHM|     20550.0|          3|           NY|       20553.0|                2|         1|      Z|      K|      1997|07042016|     F|   null|       WT|         France|           France|     Champlain|1969-12-31 21:42:30|\n",
      "+--------+----------+----------+-------------+------------------+--------------------+-------+------------+-----------+-------------+--------------+-----------------+----------+-------+-------+----------+--------+------+-------+---------+---------------+-----------------+--------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tourism_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-heater",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
