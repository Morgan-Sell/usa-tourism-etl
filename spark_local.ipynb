{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "short-diploma",
   "metadata": {},
   "source": [
    "# Spark Local Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "powered-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id, row_number\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType, DateType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-creek",
   "metadata": {},
   "source": [
    "## Configure Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "combined-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recreational-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = \"test_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stuck-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure = SparkConf().setAppName('udac_config').setMaster('local')\n",
    "sc = SparkContext(conf = configure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fuzzy-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getOrCreate modifies the parameters of existing Spark Session\n",
    "spark = SparkSession.builder.appName('udac_cap').config('config option', 'config value').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "medical-assist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/Users/morgan/Documents/10_Udacity/data_eng_nano/usa-tourism-etl/spark-warehouse'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'local-1616306143864'),\n",
       " ('spark.driver.host', '10.0.0.223'),\n",
       " ('spark.app.name', 'udac_config'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.startTime', '1616306143637'),\n",
       " ('spark.driver.port', '58887'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-israeli",
   "metadata": {},
   "source": [
    "### Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "short-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = spark.read.option(\"header\", True).csv(\"data/airport_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "varying-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = F.split(airports.coordinates, \",\")\n",
    "airports = airports.withColumn('longitude', lat_long.getItem(0))\n",
    "airports = airports.withColumn('latitude', lat_long.getItem(1))\n",
    "\n",
    "region_split = F.split(airports.iso_region, \"-\")\n",
    "airports = airports.withColumn('state', region_split.getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "french-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.select(['ident',\n",
    "                 'iata_code',\n",
    "                 'name','type',\n",
    "                 'municipality',\n",
    "                 'state',\n",
    "                 'local_code',\n",
    "                 'latitude',\n",
    "                 'longitude',\n",
    "                 'elevation_ft']).where(airports.iso_country==\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "identified-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.sort('iata_code', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "democratic-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.na.drop(subset='iata_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "variable-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = airports.withColumn(\"latitude\", airports.latitude.cast('float'))\n",
    "airports = airports.withColumn(\"longitude\", airports.longitude.cast('float'))\n",
    "aiprots = airports.withColumn(\"elevation_fit\", airports.elevation_ft.cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "emotional-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+\n",
      "|ident|iata_code|                name|          type| municipality|state|local_code|latitude|longitude|elevation_ft|\n",
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+\n",
      "| KAAF|      AAF|Apalachicola Regi...| small_airport| Apalachicola|   FL|       AAF| 29.7275| -85.0275|          20|\n",
      "| KAAP|      AAP|      Andrau Airpark|        closed|      Houston|   TX|       AAP| 29.7225| -95.5883|          79|\n",
      "| KABE|      ABE|Lehigh Valley Int...|medium_airport|    Allentown|   PA|       ABE| 40.6521| -75.4408|         393|\n",
      "| KABI|      ABI|Abilene Regional ...|medium_airport|      Abilene|   TX|       ABI| 32.4113| -99.6819|        1791|\n",
      "| PAFM|      ABL|      Ambler Airport|medium_airport|       Ambler|   AK|       AFM| 67.1063| -157.857|         334|\n",
      "| KABQ|      ABQ|Albuquerque Inter...| large_airport|  Albuquerque|   NM|       ABQ| 35.0402| -106.609|        5355|\n",
      "| KABR|      ABR|Aberdeen Regional...|medium_airport|     Aberdeen|   SD|       ABR| 45.4491| -98.4218|        1302|\n",
      "| KABY|      ABY|Southwest Georgia...|medium_airport|       Albany|   GA|       ABY| 31.5355| -84.1945|         197|\n",
      "| KACB|      ACB|Antrim County Air...| small_airport|     Bellaire|   MI|       ACB| 44.9886| -85.1984|         623|\n",
      "| KACK|      ACK|Nantucket Memoria...|medium_airport|    Nantucket|   MA|       ACK| 41.2531| -70.0602|          47|\n",
      "| KACT|      ACT|Waco Regional Air...|medium_airport|         Waco|   TX|       ACT| 31.6113| -97.2305|         516|\n",
      "| KACV|      ACV|California Redwoo...|medium_airport|Arcata/Eureka|   CA|       ACV| 40.9781| -124.109|         221|\n",
      "| KACY|      ACY|Atlantic City Int...|medium_airport|Atlantic City|   NJ|       ACY| 39.4576| -74.5772|          75|\n",
      "| KADG|      ADG|Lenawee County Ai...| small_airport|       Adrian|   MI|       ADG| 41.8677| -84.0773|         798|\n",
      "| PADK|      ADK|        Adak Airport|medium_airport|  Adak Island|   AK|       ADK|  51.878| -176.646|          18|\n",
      "| KADM|      ADM|Ardmore Municipal...| small_airport|      Ardmore|   OK|       ADM|34.30301|-97.01963|         777|\n",
      "| PADQ|      ADQ|      Kodiak Airport|medium_airport|       Kodiak|   AK|       ADQ|   57.75| -152.494|          78|\n",
      "| KPHH|      ADR|Robert F Swinnie ...| small_airport|      Andrews|   SC|       PHH| 33.4517| -79.5262|          26|\n",
      "| KADS|      ADS|     Addison Airport| small_airport|       Dallas|   TX|       ADS| 32.9686| -96.8364|         644|\n",
      "| KADH|      ADT|Ada Regional Airport| small_airport|          Ada|   OK|       ADH| 34.8043| -96.6713|        1016|\n",
      "+-----+---------+--------------------+--------------+-------------+-----+----------+--------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-thing",
   "metadata": {},
   "source": [
    "#### Successfully created parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "narrative-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "#airports.write.mode('overwrite').parquet(os.path.join(output_data, \"airports\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-treasury",
   "metadata": {},
   "source": [
    "---\n",
    "## USA Cities Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "known-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = spark.read.option('header', True) \\\n",
    "        .option('delimiter', \";\") \\\n",
    "        .csv(\"data/us_cities_demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "considered-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.withColumnRenamed(\"City\", \"city\") \\\n",
    "        .withColumnRenamed(\"State\", \"state\") \\\n",
    "        .withColumnRenamed(\"Median Age\", \"median_age\") \\\n",
    "        .withColumnRenamed(\"Male Population\", \"male_pop\") \\\n",
    "        .withColumnRenamed(\"Female Population\", \"female_pop\") \\\n",
    "        .withColumnRenamed(\"Total Population\", \"total_pop\") \\\n",
    "        .withColumnRenamed(\"Number of Veterans\", \"num_veterans\") \\\n",
    "        .withColumnRenamed(\"Foreign-born\", \"num_foreigners\") \\\n",
    "        .withColumnRenamed(\"Average Household Size\", \"avg_household_size\") \\\n",
    "        .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "        .withColumnRenamed(\"Race\", \"race\") \\\n",
    "        .withColumnRenamed(\"Count\", \"race_pop\")\n",
    "\n",
    "cities = cities.withColumn(\"state_city\", F.concat_ws(\"_\", cities.state_code, cities.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "tested-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_vars = [\"male_pop\", \"female_pop\", \"total_pop\", \"num_veterans\", \"num_foreigners\", \"race_pop\"]\n",
    "float_vars = [\"median_age\", \"avg_household_size\"]\n",
    "\n",
    "for i_var in integer_vars:\n",
    "    cities = cities.withColumn(i_var, cities[i_var].cast('integer'))\n",
    "    \n",
    "for f_var in float_vars:\n",
    "    cities = cities.withColumn(f_var, cities[f_var].cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "weird-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2 = cities.dropDuplicates([\"state_city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "solar-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_count = cities.select(\"state_city\", \"race\", \"race_pop\")\n",
    "race_count = race_count.withColumn(\"race_pop\", race_count.race_pop.cast('float'))\n",
    "race_count = race_count.groupBy(\"state_city\").pivot(\"race\").agg(F.first(\"race_pop\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "demonstrated-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_final = cities2.join(race_count, cities2.state_city == race_count.state_city)\n",
    "cities_final = cities_final.drop(\"race\", \"race_pop\", \"state_city\", \"state_city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "finnish-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_final = cities_final.withColumnRenamed(\"American Indian and Alaska Native\", \"native_american_pop\") \\\n",
    "                            .withColumnRenamed(\"Asian\", \"asian_pop\") \\\n",
    "                            .withColumnRenamed(\"Black or African-American\", \"black_american_pop\") \\\n",
    "                            .withColumnRenamed(\"Hispanic or Latino\", \"hispanic_pop\") \\\n",
    "                            .withColumnRenamed(\"White\", \"white_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fitted-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_pop: integer (nullable = true)\n",
      " |-- female_pop: integer (nullable = true)\n",
      " |-- total_pop: integer (nullable = true)\n",
      " |-- num_veterans: integer (nullable = true)\n",
      " |-- num_foreigners: integer (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- native_american_pop: float (nullable = true)\n",
      " |-- asian_pop: float (nullable = true)\n",
      " |-- black_american_pop: float (nullable = true)\n",
      " |-- hispanic_pop: float (nullable = true)\n",
      " |-- white_pop: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_final.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-stress",
   "metadata": {},
   "source": [
    "#### Successfully created parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "sized-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cities_final.write.mode('overwrite').parquet(os.path.join(output_data, \"cities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-rescue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
