{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-april",
   "metadata": {},
   "source": [
    "# Exploratory Data Analsis and Project Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sql_queries import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-classification",
   "metadata": {},
   "source": [
    "### General Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv('data/airport_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = pd.Timestamp('1960-1-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/I94_SAS_Labels_Descriptions.sas') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace(\"\\t\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(f_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-relief",
   "metadata": {},
   "source": [
    "---\n",
    "## Airports\n",
    "\n",
    "#### Notes\n",
    "- Use iata_code as unique identifies. IATA = International Airport Transport Association\n",
    "\n",
    "\n",
    "#### Extract Conditions\n",
    "- iso_country = \"US\"\n",
    "- type = \"large_airport\" or \"medium_airport\"\n",
    "\n",
    "\n",
    "#### Errors\n",
    "- Duplicate values\n",
    "- Missing values - Do not accep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_airports = airports[airports.iso_country == 'US'].copy()\n",
    "usa_airports.dropna(subset=['iata_code'], how='any', inplace=True)\n",
    "usa_airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_null_val_heatmap(usa_airports, \"USA Airports - Null Value\", (15,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-priority",
   "metadata": {},
   "source": [
    "---\n",
    "## USA Cities Demographics\n",
    "\n",
    "#### Notes\n",
    "- Can I join the `cities` dataset to `airports` dataset by the `City` feature  to the `municipality` feature?\n",
    "- There are 3 missing states - Vermont, West Virginia, and Wyoming.\n",
    "- The dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000.\n",
    "- Should I scrape the census for additional data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv('data/us_cities_demographics.csv', delimiter=';')\n",
    "cities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.columns = [\"city\", \"state\", \"median_age\", \"male_pop\", \"female_pop\", \"total_pop\", \"num_veterans\", \"num_foreigners\",\n",
    "                  \"avg_hh_size\", \"state_code\", \"race\", \"count\"]\n",
    "cities.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.sort_values([\"state\", \"city\", \"count\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities2 = cities.drop_duplicates(subset=[\"state\", \"city\"],\n",
    "                                keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cities2['total_pop']) == sum(cities['count']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cities2['total_pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cities['count']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-height",
   "metadata": {},
   "source": [
    "---\n",
    "## Visits\n",
    "\n",
    "Need to convert countries to name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.read_csv('data/immigration_data_sample.csv')\n",
    "\n",
    "visits.rename({'Unnamed: 0': 'visit_id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visits.iloc[:, :30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits['arrdate'] = pd.to_timedelta(visits.arrdate, unit='D') + start_epoch\n",
    "visits['depdate'] = pd.to_timedelta(visits.depdate, unit='D') + start_epoch\n",
    "visits['biryear'] = visits.biryear.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feats_to_drop =[\"insnum\", \"dtadfile\", \"fltno\", 'i94bir', \"occup\", \"admnum\", \"entdepu\", \"visapost\"]\n",
    "#visits.drop(feats_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_null_val_heatmap(visits, \"Tourist Visits - Null Value\", (20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits[visits.matflag!=\"M\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(visits.entdepa.unique())\n",
    "set2 = set(visits.entdepd.unique())\n",
    "\n",
    "set1.union(set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(visits.entdepd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(visits.entdepa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in visits.columns:\n",
    "    print(f\"{col}: {visits[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits.matflag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-finland",
   "metadata": {},
   "source": [
    "---\n",
    "## Global Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('data/GlobalLandTemperaturesByCity.csv')\n",
    "weather = weather[weather.Country == 'United States'].copy()\n",
    "weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_usa_cities = len(weather.City.unique())\n",
    "print(f\"# of unique US Cities: {num_unique_usa_cities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Earliest date: \", weather.dt.min())\n",
    "print(\"Latest date: \", weather.dt.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('temperatures_by_city.csv')\n",
    "weather = weather[weather.Country == 'United States'].copy()\n",
    "\n",
    "print(\"Earliest date: \", weather.dt.min())\n",
    "print(\"Latest date: \", weather.dt.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-ghana",
   "metadata": {},
   "source": [
    "---\n",
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_sas('data/I94_SAS_Labels_Descriptions.sas', 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of cities that exist in BOTH \"cities\" and \"usa_med_large\" dfs.\n",
    "# \"cities\" has a total of 2,891 cities.\n",
    "len(set(cities.City).intersection(set(usa_med_large.municipality)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
